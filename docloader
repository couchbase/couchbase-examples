#!/usr/bin/env python
# -*- python -*-

import sys
import zipfile
import os
import os.path
import simplejson as json
import tempfile
import re
from optparse import OptionParser

from couchbase import client

def parse_args():
    usage = "usage: %prog [options] <directory>|zipfile\n\n" + \
            "Example: %prog -u Administrator -p password -n 127.0.0.1:8091 " + \
            "-b mybucket -s 100 gamesim-sample.zip"

    parser = OptionParser(usage)

    username = os.environ.get('REST_USERNAME', 'Administrator')
    password = os.environ.get('REST_PASSWORD', 'password')

    parser.add_option('-u', dest='username', default=username,
                      help='Username', metavar='Administrator')
    parser.add_option('-p', dest='password', default=password,
                      help='Password', metavar='password')
    parser.add_option('-b', dest='bucket', default='gamesim-sample',
                      help='Bucket', metavar='gamesim-sample')
    parser.add_option('-n', dest='node', default='127.0.0.1:8091',
                      help='Node address', metavar='127.0.0.1:8091')
    parser.add_option('-s', dest='ram_quota', default=100, type='int',
                      help='RAM quota in MB', metavar=100)

    options, args = parser.parse_args()

    if not args:
        parser.print_help()
        sys.exit()

    return (options.username, options.password, options.node, options.bucket,
           options.ram_quota, args)

def save_doc(bucket, dockey, fp, views):
    buf = fp.read()
    result = json.loads(buf)
    if isinstance(result, dict):
        if '_id' not in result:
            bucket.set(dockey, 0, 0, json.dumps(result))
        else:
            try:
                result['_id'] = result['_id'].encode('UTF-8')
                doc_id = bucket.save(result)
                print "just now saving", doc_id
            except:
                doc_id = "_design/testing"
            if result['_id'] and 'views' in result:
                for key in result['views'].iterkeys():
                    viewpath = result['_id'] + '/_view/' + key
                    views.append(viewpath)

def gen_dockey(filename):
    fileslashed = re.split(".json", filename)
    fileinlist = re.split("/", fileslashed[0])
    file_for_key = fileinlist.pop()
    return file_for_key

def list_files(bucket, dir, views):
    basedir = dir
    #print "Files in ", os.path.abspath(dir), ": "
    subdirlist = []
    for item in os.listdir(dir):
        if os.path.isfile(os.path.join(basedir, item)):
            try:
                fp = open(os.path.join(basedir, item), 'r')
                print "working with ", item
                dockey = gen_dockey(item)
                save_doc(bucket, dockey, fp, views)
                fp.close()
            except IOError, error:
                print error
        else:
            subdirlist.append(os.path.join(basedir, item))
    for subdir in subdirlist:
        list_files(bucket, subdir, views)

def unzip_file_and_upload(bucket,file, views):
    zfobj = zipfile.ZipFile(file)
    for name in zfobj.namelist():
        if not name.endswith('/'):
            print 'working with ', name
            dockey = gen_dockey(name)
            temp = tempfile.NamedTemporaryFile()
            fname = temp.name
            temp.write(zfobj.read(name))
            temp.flush()
            try:
                fp = open(fname, 'r')
                save_doc(bucket, dockey, fp, views)
                fp.close()
            except IOError, error:
                print error
            temp.close()

def populate_docs(bucket, dir, views):
    if dir.endswith('.zip'):
        unzip_file_and_upload(bucket, dir, views)
    else:
        list_files(bucket, dir, views)

def main():
    user, pswd, host, bucket, ram_quota_mb, args = parse_args()
    print user,pswd,host,bucket, ram_quota_mb, args
    cb = client.Server(host, user, pswd)

    try:
        newbucket = cb.create(bucket, ram_quota_mb=ram_quota_mb, replica=1)
    except:
        newbucket = cb[bucket]

    #upload documents
    dir = args[0]
    views = []
    populate_docs(newbucket, dir, views)

    # execute views at least once
    for viewpath in views:
        rows = newbucket.view(viewpath, stale="update_after")

if __name__ == '__main__':
    main()
    os._exit(0)
